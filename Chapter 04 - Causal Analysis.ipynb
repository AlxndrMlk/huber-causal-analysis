{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c54c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b390095c",
   "metadata": {},
   "source": [
    "# *Causal Analysis* by Martin Huber (2023) || `Python code`\n",
    "\n",
    "\n",
    "<br>\n",
    "<img src=\"img/Bild Causal Analysis.JPG\" width=150 align=\"center\">\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "This is a **Jupyter Notebook** adaptation of [**Python code**](https://www.unifr.ch/appecon/en/assets/public/uploads/causal%20analysis%20-%20python%20examples_09.01.24.txt) for [**Causal Analysis**: Impact Evaluation and Causaal Machine Learning with Applications in R](https://amzn.to/3tCqu2z) by [Martin Huber](https://twitter.com/CausalHuber) (2023).\n",
    "\n",
    "<br>\n",
    "\n",
    "To create the Conda environment:\n",
    "\n",
    "`conda env create -f causal-martin-huber-book.yml`\n",
    "\n",
    "<br>\n",
    "\n",
    "Adapted by [**Aleksander Molak**](https://alxndr.io) / [**CausalPython**](https://causalpython.io).\n",
    "\n",
    "<a href=\"https://causalpython.io\"><img src=\"img/CausalPython.io__flat.png\" width=200 align=\"left\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51233df1",
   "metadata": {},
   "source": [
    "## Chapter 04\n",
    "### Selection on Observables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbd37ea",
   "metadata": {},
   "source": [
    "#### Snippet 01\n",
    "\n",
    "Using OLS with interactions for back-door control "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "899c1186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "def demean_col(col):\n",
    "    return col.sub(col.mean())\n",
    "\n",
    "def interaction_with_treatment(col):\n",
    "    return col.mul(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02f76598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('data/lalonde.csv').dropna()\n",
    "\n",
    "# Define the treatment (job training)\n",
    "D = df['treat']\n",
    "\n",
    "# Define the ouctome\n",
    "Y = df['re78']\n",
    "\n",
    "# Define the covariates\n",
    "X = df[['age', 'educ', 'nodegr', 'married', 'black', 'hisp', 're74', 're75', 'u74', 'u75']]\n",
    "\n",
    "# Define interaction terms between treatment and demeaned covariates\n",
    "DX_demeaned = X.apply(demean_col).apply(interaction_with_treatment)\n",
    "\n",
    "# Rename interaction cols\n",
    "DX_demeaned = DX_demeaned.rename(\n",
    "    columns={colname: f'{colname}*treat' for colname in X.columns}\n",
    ")\n",
    "\n",
    "# Concatenate (D, X, interaction_terms)\n",
    "V = pd.concat([D, X, DX_demeaned], axis=1)\n",
    "\n",
    "# Add constant for statsmodels\n",
    "V = sm.add_constant(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf8b10f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>re78</td>       <th>  R-squared:         </th> <td>   0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 04 Jul 2024</td> <th>  Prob (F-statistic):</th>  <td>0.00377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:52:16</td>     <th>  Log-Likelihood:    </th> <td> -4522.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   445</td>      <th>  AIC:               </th> <td>   9089.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   423</td>      <th>  BIC:               </th> <td>   9179.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    21</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC0</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td> 7161.1626</td> <td> 3757.536</td> <td>    1.906</td> <td> 0.057</td> <td> -203.473</td> <td> 1.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>treat</th>         <td> 1583.4679</td> <td>  650.244</td> <td>    2.435</td> <td> 0.015</td> <td>  309.012</td> <td> 2857.924</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>           <td>   40.7101</td> <td>   45.500</td> <td>    0.895</td> <td> 0.371</td> <td>  -48.468</td> <td>  129.888</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>          <td>   82.1505</td> <td>  205.548</td> <td>    0.400</td> <td> 0.689</td> <td> -320.717</td> <td>  485.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nodegr</th>        <td> -168.8203</td> <td> 1052.340</td> <td>   -0.160</td> <td> 0.873</td> <td>-2231.370</td> <td> 1893.729</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>married</th>       <td> -738.1153</td> <td>  952.402</td> <td>   -0.775</td> <td> 0.438</td> <td>-2604.789</td> <td> 1128.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>         <td>-3131.3467</td> <td> 1316.001</td> <td>   -2.379</td> <td> 0.017</td> <td>-5710.661</td> <td> -552.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hisp</th>          <td> -927.3272</td> <td> 1590.415</td> <td>   -0.583</td> <td> 0.560</td> <td>-4044.484</td> <td> 2189.829</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>re74</th>          <td>   -0.0070</td> <td>    0.094</td> <td>   -0.075</td> <td> 0.941</td> <td>   -0.192</td> <td>    0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>re75</th>          <td>    0.0011</td> <td>    0.202</td> <td>    0.005</td> <td> 0.996</td> <td>   -0.394</td> <td>    0.396</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>u74</th>           <td>-2725.3414</td> <td> 1345.558</td> <td>   -2.025</td> <td> 0.043</td> <td>-5362.587</td> <td>  -88.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>u75</th>           <td>  797.5780</td> <td> 1097.988</td> <td>    0.726</td> <td> 0.468</td> <td>-1354.439</td> <td> 2949.595</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age*treat</th>     <td>   17.2727</td> <td>   91.228</td> <td>    0.189</td> <td> 0.850</td> <td> -161.532</td> <td>  196.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ*treat</th>    <td>  466.0790</td> <td>  385.936</td> <td>    1.208</td> <td> 0.227</td> <td> -290.342</td> <td> 1222.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nodegr*treat</th>  <td> -601.8614</td> <td> 2034.914</td> <td>   -0.296</td> <td> 0.767</td> <td>-4590.219</td> <td> 3386.497</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>married*treat</th> <td> 1673.8121</td> <td> 1726.946</td> <td>    0.969</td> <td> 0.332</td> <td>-1710.939</td> <td> 5058.563</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black*treat</th>   <td> 2540.9405</td> <td> 2114.028</td> <td>    1.202</td> <td> 0.229</td> <td>-1602.479</td> <td> 6684.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hisp*treat</th>    <td> 2189.4167</td> <td> 3216.569</td> <td>    0.681</td> <td> 0.496</td> <td>-4114.943</td> <td> 8493.776</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>re74*treat</th>    <td>    0.2996</td> <td>    0.290</td> <td>    1.032</td> <td> 0.302</td> <td>   -0.269</td> <td>    0.868</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>re75*treat</th>    <td>    0.0108</td> <td>    0.286</td> <td>    0.038</td> <td> 0.970</td> <td>   -0.550</td> <td>    0.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>u74*treat</th>     <td> 9646.2296</td> <td> 3186.541</td> <td>    3.027</td> <td> 0.002</td> <td> 3400.725</td> <td> 1.59e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>u75*treat</th>     <td>-4850.0598</td> <td> 3025.866</td> <td>   -1.603</td> <td> 0.109</td> <td>-1.08e+04</td> <td> 1080.528</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.273</td> <th>  Durbin-Watson:     </th> <td>   2.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2611.987</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.245</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>13.987</td>  <th>  Cond. No.          </th> <td>1.17e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC0)<br/>[2] The condition number is large, 1.17e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       re78       & \\textbf{  R-squared:         } &     0.104   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.060   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     2.074   \\\\\n",
       "\\textbf{Date:}             & Thu, 04 Jul 2024 & \\textbf{  Prob (F-statistic):} &  0.00377    \\\\\n",
       "\\textbf{Time:}             &     10:52:16     & \\textbf{  Log-Likelihood:    } &   -4522.3   \\\\\n",
       "\\textbf{No. Observations:} &         445      & \\textbf{  AIC:               } &     9089.   \\\\\n",
       "\\textbf{Df Residuals:}     &         423      & \\textbf{  BIC:               } &     9179.   \\\\\n",
       "\\textbf{Df Model:}         &          21      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &       HC0        & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                       & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}         &    7161.1626  &     3757.536     &     1.906  &         0.057        &     -203.473    &     1.45e+04     \\\\\n",
       "\\textbf{treat}         &    1583.4679  &      650.244     &     2.435  &         0.015        &      309.012    &     2857.924     \\\\\n",
       "\\textbf{age}           &      40.7101  &       45.500     &     0.895  &         0.371        &      -48.468    &      129.888     \\\\\n",
       "\\textbf{educ}          &      82.1505  &      205.548     &     0.400  &         0.689        &     -320.717    &      485.018     \\\\\n",
       "\\textbf{nodegr}        &    -168.8203  &     1052.340     &    -0.160  &         0.873        &    -2231.370    &     1893.729     \\\\\n",
       "\\textbf{married}       &    -738.1153  &      952.402     &    -0.775  &         0.438        &    -2604.789    &     1128.559     \\\\\n",
       "\\textbf{black}         &   -3131.3467  &     1316.001     &    -2.379  &         0.017        &    -5710.661    &     -552.033     \\\\\n",
       "\\textbf{hisp}          &    -927.3272  &     1590.415     &    -0.583  &         0.560        &    -4044.484    &     2189.829     \\\\\n",
       "\\textbf{re74}          &      -0.0070  &        0.094     &    -0.075  &         0.941        &       -0.192    &        0.178     \\\\\n",
       "\\textbf{re75}          &       0.0011  &        0.202     &     0.005  &         0.996        &       -0.394    &        0.396     \\\\\n",
       "\\textbf{u74}           &   -2725.3414  &     1345.558     &    -2.025  &         0.043        &    -5362.587    &      -88.095     \\\\\n",
       "\\textbf{u75}           &     797.5780  &     1097.988     &     0.726  &         0.468        &    -1354.439    &     2949.595     \\\\\n",
       "\\textbf{age*treat}     &      17.2727  &       91.228     &     0.189  &         0.850        &     -161.532    &      196.077     \\\\\n",
       "\\textbf{educ*treat}    &     466.0790  &      385.936     &     1.208  &         0.227        &     -290.342    &     1222.500     \\\\\n",
       "\\textbf{nodegr*treat}  &    -601.8614  &     2034.914     &    -0.296  &         0.767        &    -4590.219    &     3386.497     \\\\\n",
       "\\textbf{married*treat} &    1673.8121  &     1726.946     &     0.969  &         0.332        &    -1710.939    &     5058.563     \\\\\n",
       "\\textbf{black*treat}   &    2540.9405  &     2114.028     &     1.202  &         0.229        &    -1602.479    &     6684.360     \\\\\n",
       "\\textbf{hisp*treat}    &    2189.4167  &     3216.569     &     0.681  &         0.496        &    -4114.943    &     8493.776     \\\\\n",
       "\\textbf{re74*treat}    &       0.2996  &        0.290     &     1.032  &         0.302        &       -0.269    &        0.868     \\\\\n",
       "\\textbf{re75*treat}    &       0.0108  &        0.286     &     0.038  &         0.970        &       -0.550    &        0.571     \\\\\n",
       "\\textbf{u74*treat}     &    9646.2296  &     3186.541     &     3.027  &         0.002        &     3400.725    &     1.59e+04     \\\\\n",
       "\\textbf{u75*treat}     &   -4850.0598  &     3025.866     &    -1.603  &         0.109        &    -1.08e+04    &     1080.528     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 252.273 & \\textbf{  Durbin-Watson:     } &    2.114  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2611.987  \\\\\n",
       "\\textbf{Skew:}          &   2.245 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  13.987 & \\textbf{  Cond. No.          } & 1.17e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors are heteroscedasticity robust (HC0) \\newline\n",
       " [2] The condition number is large, 1.17e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   re78   R-squared:                       0.104\n",
       "Model:                            OLS   Adj. R-squared:                  0.060\n",
       "Method:                 Least Squares   F-statistic:                     2.074\n",
       "Date:                Thu, 04 Jul 2024   Prob (F-statistic):            0.00377\n",
       "Time:                        10:52:16   Log-Likelihood:                -4522.3\n",
       "No. Observations:                 445   AIC:                             9089.\n",
       "Df Residuals:                     423   BIC:                             9179.\n",
       "Df Model:                          21                                         \n",
       "Covariance Type:                  HC0                                         \n",
       "=================================================================================\n",
       "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "const          7161.1626   3757.536      1.906      0.057    -203.473    1.45e+04\n",
       "treat          1583.4679    650.244      2.435      0.015     309.012    2857.924\n",
       "age              40.7101     45.500      0.895      0.371     -48.468     129.888\n",
       "educ             82.1505    205.548      0.400      0.689    -320.717     485.018\n",
       "nodegr         -168.8203   1052.340     -0.160      0.873   -2231.370    1893.729\n",
       "married        -738.1153    952.402     -0.775      0.438   -2604.789    1128.559\n",
       "black         -3131.3467   1316.001     -2.379      0.017   -5710.661    -552.033\n",
       "hisp           -927.3272   1590.415     -0.583      0.560   -4044.484    2189.829\n",
       "re74             -0.0070      0.094     -0.075      0.941      -0.192       0.178\n",
       "re75              0.0011      0.202      0.005      0.996      -0.394       0.396\n",
       "u74           -2725.3414   1345.558     -2.025      0.043   -5362.587     -88.095\n",
       "u75             797.5780   1097.988      0.726      0.468   -1354.439    2949.595\n",
       "age*treat        17.2727     91.228      0.189      0.850    -161.532     196.077\n",
       "educ*treat      466.0790    385.936      1.208      0.227    -290.342    1222.500\n",
       "nodegr*treat   -601.8614   2034.914     -0.296      0.767   -4590.219    3386.497\n",
       "married*treat  1673.8121   1726.946      0.969      0.332   -1710.939    5058.563\n",
       "black*treat    2540.9405   2114.028      1.202      0.229   -1602.479    6684.360\n",
       "hisp*treat     2189.4167   3216.569      0.681      0.496   -4114.943    8493.776\n",
       "re74*treat        0.2996      0.290      1.032      0.302      -0.269       0.868\n",
       "re75*treat        0.0108      0.286      0.038      0.970      -0.550       0.571\n",
       "u74*treat      9646.2296   3186.541      3.027      0.002    3400.725    1.59e+04\n",
       "u75*treat     -4850.0598   3025.866     -1.603      0.109   -1.08e+04    1080.528\n",
       "==============================================================================\n",
       "Omnibus:                      252.273   Durbin-Watson:                   2.114\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2611.987\n",
       "Skew:                           2.245   Prob(JB):                         0.00\n",
       "Kurtosis:                      13.987   Cond. No.                     1.17e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC0)\n",
       "[2] The condition number is large, 1.17e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "ols = sm.OLS(Y, V).fit(cov_type='HC0')\n",
    "\n",
    "# Print summary\n",
    "ols.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d2f942",
   "metadata": {},
   "source": [
    "**Snippets below are work in progress** and will be updated subsequently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7cbfd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # 8\n",
    "# from causalinference import CausalModel                                                                         # load causalmodel\n",
    "# import pandas as pd                                                                                             # load pandas library\n",
    "# import numpy as np                                                                                              # load numpy library\n",
    "# df = pd.read_csv('data/lalonde.csv')                                                                            # load lalonde data\n",
    "# Y = np.asarray(df['re78'])                                                                                      # define outcome\n",
    "# D = np.asarray(df['treat'])                                                                                     # define treatment (training)\n",
    "# X = np.asarray(df[['age', 'educ', 'nodegr', 'married', 'black', 'hisp', 're74', 're75', 'u74', 'u75']])         # define covariates\n",
    "# model = CausalModel(Y,D,X)                                                                                      # define causal model\n",
    "# model.est_via_matching(weights = 'inv', matches = 1)                                                            # pair matching\n",
    "# print(model.estimates)                                                                                          # matching output\n",
    "\n",
    "# # 9\n",
    "# model = CausalModel(Y,D,X)                                                                                      # define causal model\n",
    "# model.est_via_matching(weights = 'inv', matches = 3, bias_adj = True)                                           # 1:M matching\n",
    "# print(model.estimates)                                                                                          # matching output\n",
    "\n",
    "# # 10\n",
    "# from causalinference import CausalModel\n",
    "# import pandas as pd                                                                                             # load pandas library\n",
    "# import numpy as np                                                                                              # load numpy library\n",
    "# import statsmodels.api as sm                                                                                    # load statsmodels library\n",
    "# df = pd.read_csv('data/lalonde.csv')                                                                            # load lalonde data\n",
    "# Y = df['re78']                                                                                                  # define outcome\n",
    "# D = df['treat']                                                                                                 # define treatment (training)\n",
    "# X = df[['age', 'educ', 'nodegr', 'married', 'black', 'hisp', 're74', 're75', 'u74', 'u75']]                     # define covariates\n",
    "# V = sm.add_constant(X)                                                                                          # add a constant to get an intercept\n",
    "# ps = sm.GLM(D, V, family = sm.families.Binomial()).fit().fittedvalues.astype('float')                           # propensity score by logit\n",
    "# Y = np.asarray(Y)                                                                                               # causal model needs np array\n",
    "# D = np.asarray(D)\n",
    "# ps = np.asarray(ps)      \n",
    "# model = CausalModel(Y,D,ps)                                                                                     # define causal model\n",
    "# model.est_via_matching(weights = 'inv', matches = 1, bias_adj = True)                                           # propensity score matching\n",
    "# print(model.estimates)                                                                                          # show the results\n",
    "\n",
    "# # 11\n",
    "# import numpy as np                                                                             # load numpy library\n",
    "# import pandas as pd                                                                            # load pandas library\n",
    "# from causalinference import CausalModel                                                        # import causal model\n",
    "# import statsmodels.api as sm                                                                   # load statsmodels library\n",
    "# from typing import Dict                                                                        # import dict\n",
    "# from scipy.stats import norm                                                                   # import norm\n",
    "# def make_bootstraps(data: np.array, n_bootstraps: int=100) -> Dict[str, Dict[str, np.array]]:  # create boot data\n",
    "#     dc = {}                                                                                    # initiates empty dict\n",
    "#     sample_size = data.shape[0]                                                                # get sample size  \n",
    "#     idx = [i for i in range(sample_size)]                                                      # array of index\n",
    "#     for b in range(n_bootstraps):                                                              # iterating over the number of boot.                                    \n",
    "#         sidx   = np.random.choice(idx,replace=True,size=sample_size)                           # random index                     \n",
    "#         b_samp = data.loc[sidx,:]                                                              # select boot sample\n",
    "#         oob_idx = list(set(idx) - set(sidx))                                                   # get index which where not used\n",
    "#         t_samp = np.array([])                                                                  # create empty array\n",
    "#         if oob_idx:                                                                            # if observation where not used\n",
    "#             t_samp = data.loc[oob_idx,:]                                                       # put them in test sample\n",
    "#         dc['boot_'+str(b)] = {'boot':b_samp,'test':t_samp}                                     # add boot sample and test sample to dict.\n",
    "#     return(dc)                                                                                 # return dict.\n",
    "# df = pd.read_csv('data/lalonde.csv')                                                           # load lalonde data\n",
    "# df_boot = make_bootstraps(df, 999)                                                             # run 999 boot data\n",
    "# att = np.array([])                                                                             # create empty array for att values\n",
    "# for b in df_boot:                                                                              # iterate over boot data\n",
    "#     Y = df_boot[b]['boot'].loc[:, 're78'].values.reshape(-1,1)                                 # get boot outcome\n",
    "#     D = df_boot[b]['boot'].loc[:, 'treat'].values.reshape(-1,1)                                # get boot treatment\n",
    "#     X = df_boot[b]['boot'][['age', 'educ', 'nodegr', 'married', 'black', 'hisp', 're74', 're75', 'u74', 'u75']].values.reshape(-1,10) # get boot covariates\n",
    "#     V = sm.add_constant(X)                                                                     # add a constant to get an intercept\n",
    "#     ps = sm.GLM(D, V, family = sm.families.Binomial()).fit().fittedvalues.astype('float')      # propensity score by logit\n",
    "#     Y = np.asarray(Y)                                                                          # causal model needs np array\n",
    "#     D = np.asarray(D)\n",
    "#     ps = np.asarray(ps)      \n",
    "#     model = CausalModel(Y,D,ps)                                                                # define causal model\n",
    "#     model.est_via_matching(weights = 'inv', matches = 1, bias_adj = True)                      # propensity score matching\n",
    "#     att = np.concatenate((att,model.estimates['matching']['att'].flatten()))                   # store att value\n",
    "# print(f'att: {np.mean(att)}')                                                                  # print mean att\n",
    "# tstat = np.mean(att)/np.std(att)                                                               # compute t-stat.\n",
    "# p_val = 2*norm.cdf(-np.absolute(tstat))                                                        # compute p-val.\n",
    "# print(f'tstat: {tstat}\\n'                                                                      # print t-stat.\n",
    "#       f'p_val: {p_val}')                                                                       # print p-val.\n",
    "\n",
    "\n",
    "# # 12\n",
    "# import pandas as pd                                                                           # load pandas library\n",
    "# import dowhy as dw                                                                            # load dowhy library\n",
    "# import numpy as np                                                                            # load numpy library\n",
    "# df = pd.read_csv('data/lbw.csv')                                                              # load lbw data\n",
    "# df['race'] = np.where(df['race'] == 1, 1, 0)                                                  # define race as a binary indicator for white/black\n",
    "# model = dw.CausalModel(data = df,                                                             # define causal model on the data                                      \n",
    "#                        treatment = 'smoke',                                                   # define treatment (mother smoking)\n",
    "#                        outcome = 'bwt',                                                       # define outcome (birthweight in grams)\n",
    "#                        common_causes = ['race', 'age', 'lwt', 'ptl', 'ht', 'ui', 'ftv'])      # define covariates\n",
    "# identified_estimand = model.identify_effect()                                                 # identify the causal effect to be estimated\n",
    "# estimate = model.estimate_effect(identified_estimand,                                         # inverse IPW\n",
    "#                                  method_name = 'backdoor.propensity_score_weighting',         # specify the method\n",
    "#                                  target_units = 'ate',                                        # specify the target\n",
    "#                                  method_params = {'weighting_scheme': 'ips_weight'})          # specify the method parameters\n",
    "# print(estimate.value)                                                                         # show ATE\n",
    "# print(estimate.get_standard_error())                                                          # show standard error\n",
    "# print(estimate.test_stat_significance())                                                      # show p-value\n",
    "\n",
    "# # 13\n",
    "# '''\n",
    "# no Python code available\n",
    "# '''\n",
    "\n",
    "# # 14\n",
    "# import pandas as pd                                             # load pandas library\n",
    "# import doubleml as dml                                          # load doubleml library\n",
    "# from sklearn import linear_model                                # load linear_model from sklearn\n",
    "# df = pd.read_csv('data/lbw.csv')                                # load lbw data\n",
    "# df['race'] = np.where(df['race'] == 1, 1, 0)                    # define race as a binary indicator for white/black\n",
    "# X = df.loc[:, ['race', 'age', 'lwt', 'ptl', 'ht', 'ui', 'ftv']] # select covariates\n",
    "# dml_data = dml.DoubleMLData(data = df,                          # create dml_data from lbw data\n",
    "#                             y_col = 'bwt',                      # select outcome\n",
    "#                             d_cols = 'smoke',                   # select treatment\n",
    "#                             x_cols = list(X.columns.values))    # select covariates\n",
    "# ml_l = linear_model.LinearRegression()                          # define learner for E[Y|X]\n",
    "# ml_m = linear_model.LogisticRegression(max_iter = 350)          # define learner for E[D|X]\n",
    "# dr = dml.DoubleMLPLR(dml_data,                                  # double machine learning\n",
    "#                      ml_l,                                      # specify outcome model\n",
    "#                      ml_m).fit()                                # specify treatment model, fit the model\n",
    "# print(dr.summary)                                               # show the results\n",
    "\n",
    "# # 15\n",
    "# import pandas as pd                                                          # load pandas library\n",
    "# import statsmodels.api as sm                                                 # load statsmodels library\n",
    "# import numpy as np                                                           # load numpy library\n",
    "# import matplotlib.pyplot as plt                                              # load matplotlib library\n",
    "# df = pd.read_csv('data/lbw.csv')                                             # load lbw data\n",
    "# df['race'] = np.where(df['race'] == 1, 1, 0)                                 # define race as a binary indicator for white/black\n",
    "# D = df['smoke']                                                              # define treatment (mother smoking)\n",
    "# Y = df['bwt']                                                                # define outcome (birthweight in grams)\n",
    "# X = df[['race', 'age', 'lwt', 'ptl', 'ht', 'ui', 'ftv']]                     # define covariates\n",
    "# V = sm.add_constant(X)                                                       # add a constant to get an intercept\n",
    "# ps = sm.GLM(D, V, family = sm.families.Binomial()).fit().fittedvalues        # propensity score by logit\n",
    "# df['ps'] = ps                                                                # add propensity score to dataframe\n",
    "# df_treated = df.loc[df['smoke'] == 1]                                        # select treated group\n",
    "# df_nontreated = df.loc[df['smoke'] == 0]                                     # select non-treated group\n",
    "# psdens1= sm.nonparametric.KDEUnivariate(df_treated['ps']).fit()              # density of propensity score among treated\n",
    "# psdens0 = sm.nonparametric.KDEUnivariate(df_nontreated['ps']).fit()          # density of propensity score among non-treated\n",
    "# fit, axs = plt.subplots(2,2)                                                 # specify a figure with four graphs (2x2)\n",
    "# axs[0, 0].plot(psdens1.density, color = 'black')                             # plot density of ps among treated\n",
    "# axs[0, 0].set_title('Density of ps among treated')                           # set title\n",
    "# axs[0, 0].set(ylabel = 'Density')                                            # set y label\n",
    "# axs[0, 1].plot(psdens0.density, color = 'black')                             # plot density of ps among non-treated\n",
    "# axs[0, 1].set_title('Density of ps among non-treated')                       # set title\n",
    "# axs[0, 1].set(ylabel = 'Density')                                            # set y label\n",
    "# axs[1, 0].hist(df_treated['ps'], color = 'black')                            # plot histogram of ps among treated\n",
    "# axs[1, 0].set_title('Histogram of ps among treated')                         # set title\n",
    "# axs[1, 0].set(ylabel = 'Frequency')                                          # set y label\n",
    "# axs[1, 1].hist(df_nontreated['ps'], color = 'black')                         # plot histogram of ps among non-treated\n",
    "# axs[1, 1].set_title('Histogram of ps among non-treated')                     # set title\n",
    "# axs[1, 1].set(ylabel = 'Frequency')                                          # set y label\n",
    "# plt.show()                                                                   # show plot\n",
    "# psdens1.bw                                                                   # print the bandwidth for treated\n",
    "# psdens0.bw                                                                   # print the bandwidth for non-treated\n",
    "# df_treated['ps'].describe()                                                  # summary stat. for p-scores among treated\n",
    "# df_nontreated['ps'].describe()                                               # summary stat. for p-scores among non-treated\n",
    "\n",
    "# # 16\n",
    "# from causalinference import CausalModel                                      # load causalmodel\n",
    "# import pandas as pd                                                          # load pandas library\n",
    "# import numpy as np                                                           # load numpy library\n",
    "# import statsmodels.api as sm                                                 # load statsmodels library\n",
    "# import matplotlib.pyplot as plt                                              # load matplotlib library\n",
    "# df = pd.read_csv('data/lbw.csv')                                             # load lbw data\n",
    "# df['race'] = np.where(df['race'] == 1, 1, 0)                                 # define race as a binary indicator for white/black\n",
    "# D = df['smoke']                                                              # define treatment (mother smoking)\n",
    "# Y = df['bwt']                                                                # define outcome (birthweight in grams)\n",
    "# X = df[['race', 'age', 'lwt', 'ptl', 'ht', 'ui', 'ftv']]                     # define covariates\n",
    "# V = sm.add_constant(X)                                                       # add a constant to get an intercept\n",
    "# ps = sm.GLM(D, V, family = sm.families.Binomial()).fit().fittedvalues        # propensity score by logit\n",
    "# df['ps'] = ps                                                                # add propensity scores to dataframe\n",
    "# Y = np.asarray(Y)                                                            # causal model needs np array\n",
    "# D = np.asarray(D)\n",
    "# ps = np.asarray(ps)    \n",
    "# model = CausalModel(Y,D,ps)                                                  # define causal model\n",
    "# model.est_via_matching(weights = 'inv', matches = 1)                         # propensity score matching\n",
    "# model.est_propensity()                                                       # estimate prop. scores\n",
    "# df['matched_ps'] = model.propensity['fitted']                                # add matched prop. scores to dataframe\n",
    "# df_treated = df.loc[df['smoke'] == 1]                                        # select treated group\n",
    "# df_nontreated = df.loc[df['smoke'] == 0]                                     # select non-treated group\n",
    "# fit, axs = plt.subplots(2,2)                                                 # specify a figure with four graphs (2x2)\n",
    "# axs[0, 0].hist(df_treated['ps'], color = 'black')                            # plot ps among treated\n",
    "# axs[0, 0].set_title('Raw treated')                                           # set title\n",
    "# axs[0, 0].set(ylabel = 'Proportion')                                         # set y label\n",
    "# axs[0, 0].set(xlabel = 'Propensity score')                                   # set x label\n",
    "# axs[0, 1].hist(df_treated['matched_ps'], color = 'black')                    # plot ps after matching among treated\n",
    "# axs[0, 1].set_title('Matched treated')                                       # set title\n",
    "# axs[0, 1].set(ylabel = 'Proportion')                                         # set y label\n",
    "# axs[0, 1].set(xlabel = 'Propensity score')                                   # set x label\n",
    "# axs[1, 0].hist(df_nontreated['ps'], color = 'black')                         # plot ps among non-treated\n",
    "# axs[1, 0].set_title('Raw control')                                           # set title\n",
    "# axs[1, 0].set(ylabel = 'Proportion')                                         # set y label\n",
    "# axs[1, 0].set(xlabel = 'Propensity score')                                   # set x label\n",
    "# axs[1, 1].hist(df_nontreated['matched_ps'], color = 'black')                 # plot ps after matching among non-treated\n",
    "# axs[1, 1].set_title('Matched control')                                       # set title\n",
    "# axs[1, 1].set(ylabel = 'Proportion')                                         # set y label\n",
    "# axs[1, 1].set(xlabel = 'Propensity score')                                   # set x label\n",
    "# plt.show()                                                                   # show plot\n",
    "\n",
    "# # 17\n",
    "# '''\n",
    "# no Python code available\n",
    "# '''\n",
    "\n",
    "# # 18\n",
    "# import pandas as pd                                                          # load pandas library\n",
    "# import numpy as np                                                           # load numpy library\n",
    "# from zepid.causal.ipw import IPTW                                            # load iptw method from zepid library\n",
    "# from zepid.calc import counternull_pvalue                                    # load counternull_pvalue method\n",
    "# df = pd.read_csv('data/lbw.csv')                                             # load lbw data\n",
    "# df['race'] = np.where(df['race'] == 1, 1, 0)                                 # define race as a binary indicator for white/black\n",
    "# ipw = IPTW(df, treatment = 'smoke', outcome = 'ptl')                         # define ipw model\n",
    "# ipw.treatment_model('race + age + lwt + ptl + ht + ui + ftv',                # covariates\n",
    "#                     print_results = False)                                   # don't print results\n",
    "# ipw.marginal_structural_model('smoke')                                       # treatment\n",
    "# ipw.fit()                                                                    # fit the model\n",
    "# ipw.summary()                                                                # show ATE\n",
    "# counternull_pvalue(0.117, -0.274, 0.186)                                     # calculate p-val. based on SE and CI\n",
    "\n",
    "# # 19\n",
    "# '''\n",
    "# no Python code available\n",
    "# '''\n",
    "\n",
    "# # 20\n",
    "# from econml.dml import DML                                                              # load DML\n",
    "# from econml.sklearn_extensions.linear_model import StatsModelsLinearRegression          # load StatsModelsLinearReg.\n",
    "# import pandas as pd                                                                     # load pandas library\n",
    "# df = pd.read_csv('data/games.csv')                                                      # load games data\n",
    "# games_nomis = df.dropna()                                                               # drop missings\n",
    "# games_nomis.loc[:, 'is_action'] = (games_nomis.loc[:, 'genre'] == 'Action').astype(int) # create dummy for genre 'Action'\n",
    "# Y = games_nomis.loc[:,'sales'].values.ravel()                                           # define outcome\n",
    "# D = games_nomis.loc[:,'metascore'].values.ravel()                                       # define treatment\n",
    "# X = games_nomis.loc[:, ['is_action', 'year', 'userscore']]                              # define covariates\n",
    "# est = DML(model_y = 'auto',                                                             # create DML model, WeightedLassoCV for learner E[Y|X]\n",
    "#           model_t = 'auto',                                                             # WeigtedMultiTaskLassoCV for learner E[D|X]\n",
    "#           model_final = StatsModelsLinearRegression(fit_intercept=False),               # learner for fitting the outcome residuals to the treatment residuals\n",
    "#           discrete_treatment = False)                                                   # continuous treatment\n",
    "# est = est.fit(Y = Y, T = D, X = X)                                                      # fit DML model on games data                                       \n",
    "# ATE = est.effect(X = X, T0 = 0, T1 = 100)                                               # estimate treatment effect\n",
    "# lb, ub = est.effect_interval(X = X, T0 = 0, T1 = 100)                                   # estimate interval for treatment effect\n",
    "# df = list(zip(D,ATE, lb, ub))                                                           # join above results\n",
    "# df = pd.DataFrame(df).astype(float)                                                     # create dataframe with them\n",
    "# ate = df.groupby([0]).agg({1: 'mean', 2: 'mean', 3: 'mean'})                            # mean treatment effects and intervals\n",
    "# plt.figure()                                                                            # create the plot\n",
    "# ate[1].plot(label = 'ate', color = 'black', linewidth = 2)                              # add treatment line\n",
    "# ate[2].plot(label = 'lb', color = 'gray', linestyle = '--')                             # add lower bracket\n",
    "# ate[3].plot(label = 'ub', color = 'gray', linestyle = '--')                             # add upper bracket\n",
    "# plt.xlabel('Treatment level A = a')                                                     # set x label\n",
    "# plt.ylabel('E(Y^a)')                                                                    # set y label\n",
    "# plt.show()                                                                              # show the plot\n",
    "\n",
    "# # 21\n",
    "# import pandas as pd                                                              # load pandas library\n",
    "# import numpy as np                                                               # load numpy library\n",
    "# import doubleml as ml                                                            # load doubleml library\n",
    "# import multiprocessing                                                           # load multiprocessing library\n",
    "# from matplotlib import pyplot as plt                                             # load pyplot library\n",
    "# from sklearn.linear_model import LogisticRegression                              # load logistic reg. method\n",
    "# df = pd.read_csv('data/games.csv')                                               # load lbw data\n",
    "# games_nomis = df.dropna()                                                        # drop missings\n",
    "# games_nomis['metascore'] = games_nomis['metascore'] > 75                         # define binary treatment\n",
    "# games_nomis.loc[:, 'is_action'] = (games_nomis['genre'] == 'Action').astype(int) # transform action in binary var.\n",
    "# dml_data = ml.DoubleMLData(games_nomis,                                          # create dml data\n",
    "#                            y_col = 'sales',                                      # define outcome\n",
    "#                            d_cols = 'metascore',                                 # define treatment\n",
    "#                            x_cols = ['year', 'userscore', 'is_action'])          # define covariates\n",
    "# ml_g = LogisticRegression()                                                      # learner for nuisance elements\n",
    "# ml_m = LogisticRegression()                                                      # learner for prop. nuisance fcts\n",
    "# tau_vect = np.arange(0.1, 1, 0.05)                                               # ranks where we want to estiamte QTE\n",
    "# ncores = multiprocessing.cpu_count()                                             # how many cpu computer has\n",
    "# cores_used = np.min([5, ncores-1])                                               # how many cores we will use\n",
    "# qte = ml.DoubleMLQTE(dml_data,                                                   # QTE, specify the data\n",
    "#                      ml_g,                                                       # learner for nuisance elements\n",
    "#                      ml_m,                                                       # learner for prop. nuisance fcts\n",
    "#                      quantiles=tau_vect).fit()                                   # ranks, fit the QTE to our data\n",
    "# print(qte)                                                                       # show results\n",
    "# ci_qte = qte.confint(level = 0.95)                                               # confidence intervals\n",
    "# data = {'Quantile': tau_vect,                                                    # create df for plotting, add ranks\n",
    "#         'QTE': qte.coef,                                                         # add the estimated QTE\n",
    "#         'ci_lower': ci_qte['2.5 %'],                                             # add lower ci\n",
    "#         'ci_upper': ci_qte['97.5 %']}                                            # add upper ci\n",
    "# df = pd.DataFrame(data)                                                          # generate pd dataframe\n",
    "# horiz = np.zeros(len(tau_vect))                                                  # to draw horizontal line\n",
    "# fig, ax = plt.subplots()                                                         # create plot\n",
    "# ax.plot(df['Quantile'], df['QTE'], color = 'black', marker = 'o')                # add QTE line\n",
    "# ax.plot(df['Quantile'], df['ci_lower'], color = 'black', linestyle='--')         # add lower CI\n",
    "# ax.plot(df['Quantile'], df['ci_upper'], color = 'black', linestyle='--')         # add upper CI\n",
    "# ax.plot(df['Quantile'], horiz, color = 'black')                                  # add horizontal line\n",
    "# ax.set_xlabel('Tau')                                                             # set x-axis\n",
    "# ax.set_ylabel('QTE')                                                             # set y-axis\n",
    "# plt.show()                                                                       # show the plot\n",
    "\n",
    "# # 22\n",
    "# '''\n",
    "# no Python code available\n",
    "# '''\n",
    "\n",
    "# # 23\n",
    "# '''\n",
    "# no Python code available\n",
    "# '''\n",
    "\n",
    "# # 24\n",
    "# import pandas as pd                                                              # load pandas library\n",
    "# import statsmodels.api as sm                                                     # load statsmodels library\n",
    "# from statsmodels.stats.mediation import Mediation                                # load mediation model\n",
    "# df = pd.read_csv('data/wexpect.csv')                                             # load wexpect data\n",
    "# outcome_model = sm.OLS.from_formula('wexpect2 ~ male + age + swiss + motherhighedu + fatherhighedu + business + econ + communi + businform', # outcome formula\n",
    "#                                     data = df)                                   # specify the data\n",
    "# mediator_model = sm.OLS.from_formula('business ~ econ + communi + businform + male', # mediator formula\n",
    "#                                      data = df)                                  # specify the data\n",
    "# model = Mediation(outcome_model,                                                 # mediation analysis, add outcome formula\n",
    "#                   mediator_model,                                                # add mediator formula\n",
    "#                   exposure = 'male').fit()                                       # add exposure, fit to our data\n",
    "# model.summary()                                                                  # output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
