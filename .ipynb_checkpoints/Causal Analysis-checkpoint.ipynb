{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c8fe7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.mediation import Mediation\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.base import clone\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "from causalinference import CausalModel\n",
    "from zepid.causal.ipw import IPTW\n",
    "from zepid.calc import counternull_pvalue\n",
    "\n",
    "from econml.dml import DML, CausalForestDML\n",
    "from econml.sklearn_extensions.linear_model import StatsModelsLinearRegression\n",
    "\n",
    "import doubleml as dml\n",
    "from rdrobust import rdrobust, rdplot\n",
    "\n",
    "from synthdid.synthdid import Synthdid as sdid\n",
    "from synthdid.get_data import california_prop99\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520b02d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Chapter 3\n",
    "\n",
    "# 1\n",
    "df = pd.read_csv('data/JC.csv')                                          # load JC data\n",
    "D = df['assignment']                                                     # define treatment (assignment to JC)\n",
    "Y = df['earny4']                                                         # define outcome (earnings in fourth year)\n",
    "Y[D==1].mean() - Y[D==0].mean()                                          # compute the ATE\n",
    "\n",
    "# 2\n",
    "                                                  # load pandas library\n",
    "                                           # load statsmodels library\n",
    "df = pd.read_csv('data/JC.csv')                                          # load JC data\n",
    "D = df['assignment']                                                     # define treatment (assignment to JC)\n",
    "Y = df['earny4']                                                         # define outcome (earnings in fourth year)\n",
    "D = sm.add_constant(D)                                                   # add a constant to get an intercept\n",
    "ols = sm.OLS(Y, D).fit(cov_type = 'HC0')                                 # run OLS regression with White's heteroskedasticity robust se\n",
    "print(ols.summary())                                                     # output\n",
    "\n",
    "# 3\n",
    "def make_bootstraps(data: np.array, n_bootstraps: int=100) -> Dict[str, Dict[str, np.array]]:  # create boot data\n",
    "    dc = {}                                                                                    # initiates empty dict\n",
    "    sample_size = data.shape[0]                                                                # get sample size  \n",
    "    idx = [i for i in range(sample_size)]                                                      # array of index\n",
    "    for b in range(n_bootstraps):                                                              # iterating over the number of boot.                                    \n",
    "        sidx   = np.random.choice(idx,replace=True,size=sample_size)                           # random index                     \n",
    "        b_samp = data.loc[sidx,:]                                                              # select boot sample\n",
    "        oob_idx = list(set(idx) - set(sidx))                                                   # get index which where not used\n",
    "        t_samp = np.array([])                                                                  # create empty array\n",
    "        if oob_idx:                                                                            # if observation where not used\n",
    "            t_samp = data.loc[oob_idx,:]                                                       # put them in test sample\n",
    "        dc['boot_'+str(b)] = {'boot':b_samp,'test':t_samp}                                     # add boot sample and test sample to dict.\n",
    "    return(dc)                                                                                 # return dict.\n",
    "df = pd.read_csv('data/JC.csv')                                                                # load JC data\n",
    "df_boot = make_bootstraps(df, 1999)                                                            # run 1999 boot data\n",
    "coefs = np.array([])                                                                           # create empty array for coefficients\n",
    "intrs = np.array([])                                                                           # create empty array for intercepts\n",
    "lr    = LinearRegression()                                                                     # load linear regression method\n",
    "for b in df_boot:                                                                              # iterate over boot data\n",
    "    lr.fit(df_boot[b]['boot'].loc[:,'assignment'].values.reshape(-1, 1),df_boot[b]['boot'].loc[:,'earny4'].values.reshape(-1, 1))   # run linear reg.\n",
    "    coefs = np.concatenate((coefs,lr.coef_.flatten()))                                         # store coefficients\n",
    "    intrs = np.concatenate((intrs,lr.intercept_.flatten()))                                    # store intercepts\n",
    "print(f'intercept: {np.mean(intrs)}\\n'                                                         # print mean intercept\n",
    "      f'coeficient: {np.mean(coefs)}')                                                         # print mean coefficient\n",
    "tstat = np.mean(coefs)/np.std(coefs)                                                           # compute t-stat.\n",
    "p_val = 2*norm.cdf(-np.absolute(tstat))                                                        # compute p-val.\n",
    "print(f'tstat: {tstat}\\n'                                                                      # print t-stat.\n",
    "      f'p_val: {p_val}')                                                                       # print p-val.\n",
    "\n",
    "# 4\n",
    "df = pd.read_csv('data/wexpect.csv')                                             # load wexpect data\n",
    "D1 = df['treatmentinformation']                                                  # define first treatment (wage information)\n",
    "D2 = df['treatmentorder']                                                        # define second treatment (order of questions)\n",
    "D = pd.DataFrame([D1,D2]).T                                                      # sm.OLS handle only one dataframe\n",
    "D = sm.add_constant(D)                                                           # add constant to get an intercept\n",
    "Y = df['wexpect2']                                                               # define outcome (wage expectations)\n",
    "ols = sm.OLS(Y, D).fit(cov_type = 'HC0')                                         # run OLS regression whith White's heteroskedasticity robust se\n",
    "print(ols.summary())                                                             # output\n",
    "\n",
    "# 5\n",
    "df = pd.read_csv('data/marketing.csv')                                             # load marketing data\n",
    "D = df['newspaper']                                                                # define treatment (newspaper advertising)\n",
    "Y = df['sales']                                                                    # define outcome (sales)\n",
    "x_axis = np.linspace(min(D), max(D), num = 100)                                    # define points where we evaluate \n",
    "results = sm.nonparametric.KernelReg(Y,D,'c', reg_type = 'lc').fit(x_axis)         # kernel regression\n",
    "plt.plot(x_axis, results[0], color = 'black')                                      # plot regression function\n",
    "plt.xlabel('D')                                                                    # label the x axis\n",
    "plt.ylabel('Y')                                                                    # label the y axis\n",
    "plt.show()                                                                         # show the plot\n",
    "\n",
    "# 6\n",
    "df = pd.read_csv('data/coffeeleaflet.csv').dropna()                                  # load coffeleaflet data\n",
    "D = df['treatment']                                                                  # define treatment (leaflet)\n",
    "Y = df['awarewaste']                                                                 # define outcome (aware of waste production)\n",
    "X1 = df['mumedu']                                                                    # define first covariate (education of mum)\n",
    "X2 = df['sex']                                                                       # define second covariate (gender)\n",
    "V = pd.DataFrame([D,X1,X2]).T                                                        # join parameters (treatment + covariates)\n",
    "V = sm.add_constant(V)                                                               # add a constant to get an intercept\n",
    "ols = sm.OLS(Y, V).fit(cov_type = 'HC0')                                             # run OLS regression with White's heteroskedasticity robust se\n",
    "print(ols.summary())                                                                 # output                                      \n",
    "\n",
    "# Chapter 4\n",
    "\n",
    "# 7\n",
    "df = pd.read_csv('data/lalonde.csv').dropna()                                                 # load lalonde data\n",
    "D = df['treat']                                                                               # define treatment (training)\n",
    "Y = df['re78']                                                                                # define outcome\n",
    "X = df[['age', 'educ', 'nodegr', 'married', 'black', 'hisp', 're74', 're75', 'u74', 'u75']]   # define covariates\n",
    "def demeand(column):                                                                          # handmade demeaned function\n",
    "    return column.sub(column.mean())\n",
    "cols = X.columns                                                                              # get columns of covariates\n",
    "Xdemeaned = X[cols].apply(demeand)                                                            # demeaned X\n",
    "def interaction_withD(term1):                                                                 # handmade intercation function with treatment\n",
    "    return term1.mul(D)\n",
    "DXdemeaned = Xdemeaned[cols].apply(interaction_withD)                                         # intercation of D and demeaned X\n",
    "DXdemeaned.rename(columns={'age': 'age*treat',                                                # rename interaction terms\n",
    "                           'educ': 'educ*treat',\n",
    "                           'nodegr': 'nodegr*treat',\n",
    "                           'married': 'married*treat',\n",
    "                           'black': 'black*treat',\n",
    "                           'hisp': 'hisp*treat',\n",
    "                           're74': 're74*treat',\n",
    "                           're75': 're75*treat',\n",
    "                           'u74': 'u74*treat',\n",
    "                           'u75': 'u75*treat'}, inplace = True)\n",
    "V = pd.concat([D, X, DXdemeaned], axis = 1)                                                   # join parameters (treatment, covariates, intercations)\n",
    "V = sm.add_constant(V)                                                                        # add a constant to get an intercept\n",
    "ols = sm.OLS(Y, V).fit(cov_type = 'HC0')                                                      # run OLS regression with White's heteroskedasticity robust se\n",
    "print(ols.summary())                                                                          # output\n",
    "\n",
    "# 8\n",
    "df = pd.read_csv('data/lalonde.csv')                                                                            # load lalonde data\n",
    "Y = np.asarray(df['re78'])                                                                                      # define outcome\n",
    "D = np.asarray(df['treat'])                                                                                     # define treatment (training)\n",
    "X = np.asarray(df[['age', 'educ', 'nodegr', 'married', 'black', 'hisp', 're74', 're75', 'u74', 'u75']])         # define covariates\n",
    "model = CausalModel(Y,D,X)                                                                                      # define causal model\n",
    "model.est_via_matching(weights = 'inv', matches = 1)                                                            # pair matching\n",
    "print(model.estimates)                                                                                          # matching output\n",
    "\n",
    "# 9\n",
    "model = CausalModel(Y,D,X)                                                                                      # define causal model\n",
    "model.est_via_matching(weights = 'inv', matches = 3, bias_adj = True)                                           # 1:M matching\n",
    "print(model.estimates)                                                                                          # matching output\n",
    "\n",
    "# 10\n",
    "df = pd.read_csv('data/lalonde.csv')                                                                            # load lalonde data\n",
    "Y = df['re78']                                                                                                  # define outcome\n",
    "D = df['treat']                                                                                                 # define treatment (training)\n",
    "X = df[['age', 'educ', 'nodegr', 'married', 'black', 'hisp', 're74', 're75', 'u74', 'u75']]                     # define covariates\n",
    "V = sm.add_constant(X)                                                                                          # add a constant to get an intercept\n",
    "ps = sm.GLM(D, V, family = sm.families.Binomial()).fit().fittedvalues.astype('float')                           # propensity score by logit\n",
    "Y = np.asarray(Y)                                                                                               # causal model needs np array\n",
    "D = np.asarray(D)\n",
    "ps = np.asarray(ps)      \n",
    "model = CausalModel(Y,D,ps)                                                                                     # define causal model\n",
    "model.est_via_matching(weights = 'inv', matches = 1, bias_adj = True)                                           # propensity score matching\n",
    "print(model.estimates)                                                                                          # show the results\n",
    "\n",
    "# 11\n",
    "def make_bootstraps(data: np.array, n_bootstraps: int=100) -> Dict[str, Dict[str, np.array]]:  # create boot data\n",
    "    dc = {}                                                                                    # initiates empty dict\n",
    "    sample_size = data.shape[0]                                                                # get sample size  \n",
    "    idx = [i for i in range(sample_size)]                                                      # array of index\n",
    "    for b in range(n_bootstraps):                                                              # iterating over the number of boot.                                    \n",
    "        sidx   = np.random.choice(idx,replace=True,size=sample_size)                           # random index                     \n",
    "        b_samp = data.loc[sidx,:]                                                              # select boot sample\n",
    "        oob_idx = list(set(idx) - set(sidx))                                                   # get index which where not used\n",
    "        t_samp = np.array([])                                                                  # create empty array\n",
    "        if oob_idx:                                                                            # if observation where not used\n",
    "            t_samp = data.loc[oob_idx,:]                                                       # put them in test sample\n",
    "        dc['boot_'+str(b)] = {'boot':b_samp,'test':t_samp}                                     # add boot sample and test sample to dict.\n",
    "    return(dc)                                                                                 # return dict.\n",
    "df = pd.read_csv('data/lalonde.csv')                                                           # load lalonde data\n",
    "df_boot = make_bootstraps(df, 999)                                                             # run 999 boot data\n",
    "att = np.array([])                                                                             # create empty array for att values\n",
    "for b in df_boot:                                                                              # iterate over boot data\n",
    "    Y = df_boot[b]['boot'].loc[:, 're78'].values.reshape(-1,1)                                 # get boot outcome\n",
    "    D = df_boot[b]['boot'].loc[:, 'treat'].values.reshape(-1,1)                                # get boot treatment\n",
    "    X = df_boot[b]['boot'][['age', 'educ', 'nodegr', 'married', 'black', 'hisp', 're74', 're75', 'u74', 'u75']].values.reshape(-1,10) # get boot covariates\n",
    "    V = sm.add_constant(X)                                                                     # add a constant to get an intercept\n",
    "    ps = sm.GLM(D, V, family = sm.families.Binomial()).fit().fittedvalues.astype('float')      # propensity score by logit\n",
    "    Y = np.asarray(Y)                                                                          # causal model needs np array\n",
    "    D = np.asarray(D)\n",
    "    ps = np.asarray(ps)      \n",
    "    model = CausalModel(Y,D,ps)                                                                # define causal model\n",
    "    model.est_via_matching(weights = 'inv', matches = 1, bias_adj = True)                      # propensity score matching\n",
    "    att = np.concatenate((att,model.estimates['matching']['att'].flatten()))                   # store att value\n",
    "print(f'att: {np.mean(att)}')                                                                  # print mean att\n",
    "tstat = np.mean(att)/np.std(att)                                                               # compute t-stat.\n",
    "p_val = 2*norm.cdf(-np.absolute(tstat))                                                        # compute p-val.\n",
    "print(f'tstat: {tstat}\\n'                                                                      # print t-stat.\n",
    "      f'p_val: {p_val}')                                                                       # print p-val.\n",
    "\n",
    "\n",
    "# 12\n",
    "df = pd.read_csv('data/lbw.csv')                                                              # load lbw data\n",
    "df['race'] = np.where(df['race'] == 1, 1, 0)                                                  # define race as a binary indicator for white/black\n",
    "model = dw.CausalModel(data = df,                                                             # define causal model on the data                                      \n",
    "                       treatment = 'smoke',                                                   # define treatment (mother smoking)\n",
    "                       outcome = 'bwt',                                                       # define outcome (birthweight in grams)\n",
    "                       common_causes = ['race', 'age', 'lwt', 'ptl', 'ht', 'ui', 'ftv'])      # define covariates\n",
    "identified_estimand = model.identify_effect()                                                 # identify the causal effect to be estimated\n",
    "estimate = model.estimate_effect(identified_estimand,                                         # inverse IPW\n",
    "                                 method_name = 'backdoor.propensity_score_weighting',         # specify the method\n",
    "                                 target_units = 'ate',                                        # specify the target\n",
    "                                 method_params = {'weighting_scheme': 'ips_weight'})          # specify the method parameters\n",
    "print(estimate.value)                                                                         # show ATE\n",
    "print(estimate.get_standard_error())                                                          # show standard error\n",
    "print(estimate.test_stat_significance())                                                      # show p-value\n",
    "\n",
    "# 13\n",
    "'''\n",
    "no Python code available\n",
    "'''\n",
    "\n",
    "# 14\n",
    "df = pd.read_csv('data/lbw.csv')                                                     # load lbw data\n",
    "df['race'] = np.where(df['race'] == 1, 1, 0)                                         # define race as a binary indicator for white/black\n",
    "gee = sm.GEE.from_formula('bwt ~ smoke + race + age + lwt + ptl + ht + ui + ftv',    # GEE, define the formula\n",
    "                           groups='smoke',                                           # define treatment group \n",
    "                           data=df,                                                  # define the data\n",
    "                           family=sm.families.Gaussian()).fit()                      # define the family and fit the result                                                          \n",
    "print(gee.summary())                                                                 # show results\n",
    "\n",
    "# 15\n",
    "df = pd.read_csv('data/lbw.csv')                                             # load lbw data\n",
    "df['race'] = np.where(df['race'] == 1, 1, 0)                                 # define race as a binary indicator for white/black\n",
    "D = df['smoke']                                                              # define treatment (mother smoking)\n",
    "Y = df['bwt']                                                                # define outcome (birthweight in grams)\n",
    "X = df[['race', 'age', 'lwt', 'ptl', 'ht', 'ui', 'ftv']]                     # define covariates\n",
    "V = sm.add_constant(X)                                                       # add a constant to get an intercept\n",
    "ps = sm.GLM(D, V, family = sm.families.Binomial()).fit().fittedvalues        # propensity score by logit\n",
    "df['ps'] = ps                                                                # add propensity score to dataframe\n",
    "df_treated = df.loc[df['smoke'] == 1]                                        # select treated group\n",
    "df_nontreated = df.loc[df['smoke'] == 0]                                     # select non-treated group\n",
    "psdens1= sm.nonparametric.KDEUnivariate(df_treated['ps']).fit()              # density of propensity score among treated\n",
    "psdens0 = sm.nonparametric.KDEUnivariate(df_nontreated['ps']).fit()          # density of propensity score among non-treated\n",
    "fit, axs = plt.subplots(2,2)                                                 # specify a figure with four graphs (2x2)\n",
    "axs[0, 0].plot(psdens1.density, color = 'black')                             # plot density of ps among treated\n",
    "axs[0, 0].set_title('Density of ps among treated')                           # set title\n",
    "axs[0, 0].set(ylabel = 'Density')                                            # set y label\n",
    "axs[0, 1].plot(psdens0.density, color = 'black')                             # plot density of ps among non-treated\n",
    "axs[0, 1].set_title('Density of ps among non-treated')                       # set title\n",
    "axs[0, 1].set(ylabel = 'Density')                                            # set y label\n",
    "axs[1, 0].hist(df_treated['ps'], color = 'black')                            # plot histogram of ps among treated\n",
    "axs[1, 0].set_title('Histogram of ps among treated')                         # set title\n",
    "axs[1, 0].set(ylabel = 'Frequency')                                          # set y label\n",
    "axs[1, 1].hist(df_nontreated['ps'], color = 'black')                         # plot histogram of ps among non-treated\n",
    "axs[1, 1].set_title('Histogram of ps among non-treated')                     # set title\n",
    "axs[1, 1].set(ylabel = 'Frequency')                                          # set y label\n",
    "plt.show()                                                                   # show plot\n",
    "psdens1.bw                                                                   # print the bandwidth for treated\n",
    "psdens0.bw                                                                   # print the bandwidth for non-treated\n",
    "df_treated['ps'].describe()                                                  # summary stat. for p-scores among treated\n",
    "df_nontreated['ps'].describe()                                               # summary stat. for p-scores among non-treated\n",
    "\n",
    "# 16\n",
    "df = pd.read_csv('data/lbw.csv')                                             # load lbw data\n",
    "df['race'] = np.where(df['race'] == 1, 1, 0)                                 # define race as a binary indicator for white/black\n",
    "D = df['smoke']                                                              # define treatment (mother smoking)\n",
    "Y = df['bwt']                                                                # define outcome (birthweight in grams)\n",
    "X = df[['race', 'age', 'lwt', 'ptl', 'ht', 'ui', 'ftv']]                     # define covariates\n",
    "V = sm.add_constant(X)                                                       # add a constant to get an intercept\n",
    "ps = sm.GLM(D, V, family = sm.families.Binomial()).fit().fittedvalues        # propensity score by logit\n",
    "df['ps'] = ps                                                                # add propensity scores to dataframe\n",
    "Y = np.asarray(Y)                                                            # causal model needs np array\n",
    "D = np.asarray(D)\n",
    "ps = np.asarray(ps)    \n",
    "model = CausalModel(Y,D,ps)                                                  # define causal model\n",
    "model.est_via_matching(weights = 'inv', matches = 1)                         # propensity score matching\n",
    "model.est_propensity()                                                       # estimate prop. scores\n",
    "df['matched_ps'] = model.propensity['fitted']                                # add matched prop. scores to dataframe\n",
    "df_treated = df.loc[df['smoke'] == 1]                                        # select treated group\n",
    "df_nontreated = df.loc[df['smoke'] == 0]                                     # select non-treated group\n",
    "fit, axs = plt.subplots(2,2)                                                 # specify a figure with four graphs (2x2)\n",
    "axs[0, 0].hist(df_treated['ps'], color = 'black')                            # plot ps among treated\n",
    "axs[0, 0].set_title('Raw treated')                                           # set title\n",
    "axs[0, 0].set(ylabel = 'Proportion')                                         # set y label\n",
    "axs[0, 0].set(xlabel = 'Propensity score')                                   # set x label\n",
    "axs[0, 1].hist(df_treated['matched_ps'], color = 'black')                    # plot ps after matching among treated\n",
    "axs[0, 1].set_title('Matched treated')                                       # set title\n",
    "axs[0, 1].set(ylabel = 'Proportion')                                         # set y label\n",
    "axs[0, 1].set(xlabel = 'Propensity score')                                   # set x label\n",
    "axs[1, 0].hist(df_nontreated['ps'], color = 'black')                         # plot ps among non-treated\n",
    "axs[1, 0].set_title('Raw control')                                           # set title\n",
    "axs[1, 0].set(ylabel = 'Proportion')                                         # set y label\n",
    "axs[1, 0].set(xlabel = 'Propensity score')                                   # set x label\n",
    "axs[1, 1].hist(df_nontreated['matched_ps'], color = 'black')                 # plot ps after matching among non-treated\n",
    "axs[1, 1].set_title('Matched control')                                       # set title\n",
    "axs[1, 1].set(ylabel = 'Proportion')                                         # set y label\n",
    "axs[1, 1].set(xlabel = 'Propensity score')                                   # set x label\n",
    "plt.show()                                                                   # show plot\n",
    "\n",
    "# 17\n",
    "'''\n",
    "no Python code available\n",
    "'''\n",
    "\n",
    "# 18\n",
    "df = pd.read_csv('data/lbw.csv')                                             # load lbw data\n",
    "df['race'] = np.where(df['race'] == 1, 1, 0)                                 # define race as a binary indicator for white/black\n",
    "ipw = IPTW(df, treatment = 'smoke', outcome = 'ptl')                         # define ipw model\n",
    "ipw.treatment_model('race + age + lwt + ptl + ht + ui + ftv',                # covariates\n",
    "                    print_results = False)                                   # don't print results\n",
    "ipw.marginal_structural_model('smoke')                                       # treatment\n",
    "ipw.fit()                                                                    # fit the model\n",
    "ipw.summary()                                                                # show ATE\n",
    "counternull_pvalue(0.117, -0.274, 0.186)                                     # calculate p-val. based on SE and CI\n",
    "\n",
    "# 19\n",
    "'''\n",
    "no Python code available\n",
    "'''\n",
    "\n",
    "# 20\n",
    "df = pd.read_csv('data/games.csv')                                                      # load games data\n",
    "games_nomis = df.dropna()                                                               # drop missings\n",
    "games_nomis.loc[:, 'is_action'] = (games_nomis.loc[:, 'genre'] == 'Action').astype(int) # create dummy for genre 'Action'\n",
    "Y = games_nomis.loc[:,'sales'].values.ravel()                                           # define outcome\n",
    "D = games_nomis.loc[:,'metascore'].values.ravel()                                       # define treatment\n",
    "X = games_nomis.loc[:, ['is_action', 'year', 'userscore']]                              # define covariates\n",
    "est = DML(model_y = 'auto',                                                             # create DML model, WeightedLassoCV for learner E[Y|X]\n",
    "          model_t = 'auto',                                                             # WeigtedMultiTaskLassoCV for learner E[D|X]\n",
    "          model_final = StatsModelsLinearRegression(fit_intercept=False),               # learner for fitting the outcome residuals to the treatment residuals\n",
    "          discrete_treatment = False)                                                   # continuous treatment\n",
    "est = est.fit(Y = Y, T = D, X = X)                                                      # fit DML model on games data                                       \n",
    "ATE = est.effect(X = X, T0 = 0, T1 = 100)                                               # estimate treatment effect\n",
    "lb, ub = est.effect_interval(X = X, T0 = 0, T1 = 100)                                   # estimate interval for treatment effect\n",
    "df = list(zip(D,ATE, lb, ub))                                                           # join above results\n",
    "df = pd.DataFrame(df).astype(float)                                                     # create dataframe with them\n",
    "ate = df.groupby([0]).agg({1: 'mean', 2: 'mean', 3: 'mean'})                            # mean treatment effects and intervals\n",
    "plt.figure()                                                                            # create the plot\n",
    "ate[1].plot(label = 'ate', color = 'black', linewidth = 2)                              # add treatment line\n",
    "ate[2].plot(label = 'lb', color = 'gray', linestyle = '--')                             # add lower bracket\n",
    "ate[3].plot(label = 'ub', color = 'gray', linestyle = '--')                             # add upper bracket\n",
    "plt.xlabel('Treatment level A = a')                                                     # set x label\n",
    "plt.ylabel('E(Y^a)')                                                                    # set y label\n",
    "plt.show()                                                                              # show the plot\n",
    "\n",
    "# 21\n",
    "df = pd.read_csv('data/games.csv')                                               # load lbw data\n",
    "games_nomis = df.dropna()                                                        # drop missings\n",
    "games_nomis['metascore'] = games_nomis['metascore'] > 75                         # define binary treatment\n",
    "games_nomis.loc[:, 'is_action'] = (games_nomis['genre'] == 'Action').astype(int) # transform action in binary var.\n",
    "dml_data = ml.DoubleMLData(games_nomis,                                          # create dml data\n",
    "                           y_col = 'sales',                                      # define outcome\n",
    "                           d_cols = 'metascore',                                 # define treatment\n",
    "                           x_cols = ['year', 'userscore', 'is_action'])          # define covariates\n",
    "ml_g = LogisticRegression()                                                      # learner for nuisance elements\n",
    "ml_m = LogisticRegression()                                                      # learner for prop. nuisance fcts\n",
    "tau_vect = np.arange(0.1, 1, 0.05)                                               # ranks where we want to estiamte QTE\n",
    "ncores = multiprocessing.cpu_count()                                             # how many cpu computer has\n",
    "cores_used = np.min([5, ncores-1])                                               # how many cores we will use\n",
    "qte = ml.DoubleMLQTE(dml_data,                                                   # QTE, specify the data\n",
    "                     ml_g,                                                       # learner for nuisance elements\n",
    "                     ml_m,                                                       # learner for prop. nuisance fcts\n",
    "                     quantiles=tau_vect).fit()                                   # ranks, fit the QTE to our data\n",
    "print(qte)                                                                       # show results\n",
    "ci_qte = qte.confint(level = 0.95)                                               # confidence intervals\n",
    "data = {'Quantile': tau_vect,                                                    # create df for plotting, add ranks\n",
    "        'QTE': qte.coef,                                                         # add the estimated QTE\n",
    "        'ci_lower': ci_qte['2.5 %'],                                             # add lower ci\n",
    "        'ci_upper': ci_qte['97.5 %']}                                            # add upper ci\n",
    "df = pd.DataFrame(data)                                                          # generate pd dataframe\n",
    "horiz = np.zeros(len(tau_vect))                                                  # to draw horizontal line\n",
    "fig, ax = plt.subplots()                                                         # create plot\n",
    "ax.plot(df['Quantile'], df['QTE'], color = 'black', marker = 'o')                # add QTE line\n",
    "ax.plot(df['Quantile'], df['ci_lower'], color = 'black', linestyle='--')         # add lower CI\n",
    "ax.plot(df['Quantile'], df['ci_upper'], color = 'black', linestyle='--')         # add upper CI\n",
    "ax.plot(df['Quantile'], horiz, color = 'black')                                  # add horizontal line\n",
    "ax.set_xlabel('Tau')                                                             # set x-axis\n",
    "ax.set_ylabel('QTE')                                                             # set y-axis\n",
    "plt.show()                                                                       # show the plot\n",
    "\n",
    "# 22\n",
    "'''\n",
    "no Python code available\n",
    "'''\n",
    "\n",
    "# 23\n",
    "'''\n",
    "no Python code available\n",
    "'''\n",
    "\n",
    "# 24\n",
    "df = pd.read_csv('data/wexpect.csv')                                             # load wexpect data\n",
    "outcome_model = sm.OLS.from_formula('wexpect2 ~ male + age + swiss + motherhighedu + fatherhighedu + business + econ + communi + businform', # outcome formula\n",
    "                                    data = df)                                   # specify the data\n",
    "mediator_model = sm.OLS.from_formula('business ~ econ + communi + businform + male', # mediator formula\n",
    "                                     data = df)                                  # specify the data\n",
    "model = Mediation(outcome_model,                                                 # mediation analysis, add outcome formula\n",
    "                  mediator_model,                                                # add mediator formula\n",
    "                  exposure = 'male').fit()                                       # add exposure, fit to our data\n",
    "model.summary()                                                                  # output\n",
    "\n",
    "# Chapter 5\n",
    "\n",
    "# 25\n",
    "df = pd.read_csv('data/JC.csv')                                    # load JC data\n",
    "X = df.iloc[:, 1:29]                                               # define covariates\n",
    "dml_data = dml.DoubleMLData(df,                                    # create dml data from JC data\n",
    "                            y_col = 'health48',                    # define outcome\n",
    "                            d_cols = 'trainy1',                    # define treatment\n",
    "                            x_cols = list(X.columns.values))       # define covariates\n",
    "ml_m = LogisticRegressionCV(penalty='l1',             # define learner for E[D|X], norm of the penalty\n",
    "                                         solver='saga',            # solver for multinomial loss\n",
    "                                         max_iter=300,             # max. number of iterations\n",
    "                                         Cs=1,                     # inverse of regularization strength\n",
    "                                         tol=1e-3)                 # tolerance for stopping criteria\n",
    "ml_l = LassoCV()                                      # define learner for E[Y|X]\n",
    "dml_lasso = dml.DoubleMLPLR(dml_data,                              # double machine learning, add our data\n",
    "                            ml_l,                                  # add the learner for E[Y|X]\n",
    "                            ml_m,                                  # add the learner for E[D|X]\n",
    "                            n_folds = 3).fit()                     # specify number of folds for cv, fit to our data\n",
    "print(dml_lasso.summary)                                           # output\n",
    "\n",
    "# 26\n",
    "ml_l = RandomForestRegressor()                            # define learner for E[Y|X]\n",
    "ml_m = RandomForestRegressor()                            # define learner for E[D|X]\n",
    "dml_rfg = dml.DoubleMLPLR(dml_data,                                # double machine learning\n",
    "                            ml_l,                                  # add the learner for E[Y|X]\n",
    "                            ml_m,                                  # add the learner for E[D|X]\n",
    "                            n_folds = 3).fit()                     # specify number of folds for cv, fit to our data\n",
    "print(dml_rfg.summary)                                             # output\n",
    "\n",
    "# 27\n",
    "df = pd.read_csv('data/JC.csv')                                                                         # load JC data        \n",
    "df.columns = df.columns.astype(str)                                                                     # cast column names to string\n",
    "Y = df.iloc[:, 39]                                                                                      # define outcome (pworky3)\n",
    "D = df.iloc[:, 36]                                                                                      # define treatment (trainy1)\n",
    "X = df.iloc[:, 1:29]                                                                                    # define covariates\n",
    "educ = pd.get_dummies(X['educ'])                                                                        # one-hot-encoding...\n",
    "hhsize = pd.get_dummies(X['hhsize'])                                                                    # for the scikit-learn implementation...\n",
    "educmum = pd.get_dummies(X['educmum'])                                                                  # of all categorical variables\n",
    "educdad = pd.get_dummies(X['educdad'])                                                                  # one-hot-encoding\n",
    "welfarechild = pd.get_dummies(X['welfarechild'])                                                        # one-hot encoding\n",
    "health = pd.get_dummies(X['health'])                                                                    # one-hot-encoding\n",
    "smoke = pd.get_dummies(X['smoke'])                                                                      # one-hot-encoding\n",
    "alcohol = pd.get_dummies(X['alcohol'])                                                                  # one-hot-encoding\n",
    "X.drop(columns = ['educ', 'hhsize', 'educmum', 'educdad', 'welfarechild', 'health', 'smoke', 'alcohol'],# delete categorical variables\n",
    "       axis = 1,                                                                                        # column axis\n",
    "       inplace = True)                                                                                  # dont return a copy, do it on original df\n",
    "X = pd.concat([X, educ, hhsize, educmum, educdad, welfarechild, health, smoke, alcohol], axis = 1)      # add their one-hot-encoding\n",
    "X.columns = X.columns.astype(str)                                                                       # cast column names to string\n",
    "cf = CausalForestDML(n_estimators = 2000,                                                               # create causalforest object, num. trees in r\n",
    "                     min_samples_leaf = 5,                                                              # min.node.size in r\n",
    "                     max_depth = min(round(math.sqrt(len(X.columns))) + 20, len(X.columns)),            # mtry in r\n",
    "                     model_t = RandomForestClassifier(max_depth = 5,                                    # define learner for E[D|X]\n",
    "                                                      min_samples_leaf = 10,                            # tune parameters of leaner\n",
    "                                                      random_state = 123),                              # tune parameters of learner\n",
    "                     model_y = GradientBoostingRegressor(min_samples_leaf = 30,                         # define learner for E[Y|X]\n",
    "                                                         n_estimators = 50,                             # tune parameters of learner\n",
    "                                                         random_state = 123),                           # tune parameters of learner\n",
    "                     discrete_treatment = True,                                                         # D is binary\n",
    "                     drate = True)                                                                      # compute ATE at fit time\n",
    "cf.fit(Y = Y, T = D, X = X)                                                                             # fit causalforest on JC data\n",
    "ATE = cf.ate_                                                                                           # store ATE\n",
    "SE = cf.ate_stderr_                                                                                     # store std. error of ATE\n",
    "pval = 2*norm.cdf(-abs(ATE/SE))                                                                         # compute p-value\n",
    "print(ATE, SE, pval)                                                                                    # show the results\n",
    "\n",
    "# 28\n",
    "CATE = cf.effect(X)                                         # compute cate on the JC data\n",
    "plt.hist(CATE, color = 'gray', bins = 16, rwidth = 0.9)     # create histogram of cate\n",
    "plt.xlabel('CATE')                                          # set x-axis name\n",
    "plt.ylabel('Frequency')                                     # set y-axis name\n",
    "plt.title('Histogram of CATE')                              # set title\n",
    "plt.show()                                                  # show the plot\n",
    "\n",
    "# 29\n",
    "highCATE = (CATE > np.median(CATE)).astype(int)          # dummy for high CATE\n",
    "highCATE = sm.add_constant(highCATE)                     # add constant to get an intercept\n",
    "ols = sm.OLS(df['age'], highCATE).fit(cov_type = 'HC0')  # run OLS regression with White's heteroskedasticity robust se\n",
    "print(ols.summary())                                     # output\n",
    "\n",
    "# 30\n",
    "'''\n",
    "no Python code available\n",
    "'''\n",
    "\n",
    "# 31\n",
    "cf.cate_feature_names()  # show features importance\n",
    "\n",
    "# 32\n",
    "'''\n",
    "no Python code available\n",
    "'''\n",
    "\n",
    "# Chapter 6\n",
    "\n",
    "# 33\n",
    "df = pd.read_csv('data/JC.csv')                                    # load JC data\n",
    "Z = df['assignment']                                               # define instrument\n",
    "D = df['trainy1']                                                  # define treatment\n",
    "Y = df['earny4']                                                   # define outcome\n",
    "ITT = Y[Z==1].mean() - Y[Z==0].mean()                              # estimate intention-to-treat effect\n",
    "first = D[Z==1].mean() - D[Z==0].mean()                            # estimate first stage effect (complier share)\n",
    "LATE = ITT/first                                                   # compute LATE\n",
    "print(ITT, first, LATE)                                            # show ITT, first stage effect and LATE\n",
    "\n",
    "# 34\n",
    "df = pd.read_csv('data/JC.csv')                                    # load JC data\n",
    "df = sm.add_constant(data = df, prepend = False)                   # add a constant to get an intercept\n",
    "ivreg = lm.IV2SLS(dependent = df['earny4'],                        # dependent variable\n",
    "                 endog = df['trainy1'],                            # endogeneous var.\n",
    "                 exog = df['const'],                               # exogeneous var.\n",
    "                 instruments = df['assignment'])                   # instrument\n",
    "LATE = ivreg.fit(cov_type = 'robust')                              # run 2SLS with hetero.-robust se\n",
    "LATE.summary                                                       # results\n",
    "\n",
    "# 35\n",
    "'''\n",
    "no Python code available\n",
    "'''\n",
    "\n",
    "# 36\n",
    "learner = GradientBoostingRegressor()                                                               # define learner as gb regressor\n",
    "ml_l = clone(learner)                                                                               # learner for E[Y|X]\n",
    "ml_m = clone(learner)                                                                               # learner for E[Z|X]\n",
    "ml_r = clone(learner)                                                                               # learner for E[D|X]\n",
    "np.random.seed(1)                                                                                   # set seed\n",
    "df = pd.read_csv('data/c401k.csv')                                                                  # load c401k data\n",
    "X = df.iloc[:, 4:11]                                                                                # covariates                        \n",
    "obj_dml_data = dml.DoubleMLData(df,                                                                 # create double-machine learning object\n",
    "                                y_col = 'nettfa',                                                   # define outcome\n",
    "                                d_cols = 'p401k',                                                   # define treatment\n",
    "                                x_cols = list(X.columns.values),                                    # define covariates\n",
    "                                z_cols = 'e401k')                                                   # define instrument\n",
    "dml_pliv_obj = dml.DoubleMLPLIV(obj_dml_data, ml_l, ml_m, ml_r).fit()                               # fit\n",
    "print(dml_pliv_obj.summary)                                                                         # print the results\n",
    "\n",
    "# 37\n",
    "'''\n",
    "no Python code available\n",
    "'''\n",
    "\n",
    "# Chapter 7\n",
    "\n",
    "# 38\n",
    "df = pd.read_csv('data/kielmc.csv')                                    # load kielmc data\n",
    "Y = df['rprice']                                                       # define outcome\n",
    "D = df['nearinc']                                                      # define treatment group\n",
    "T = df['y81']                                                          # define period dummy\n",
    "df['interact'] = D * T                                                 # treatment-period interaction\n",
    "x = df[['nearinc', 'y81', 'interact']]                                 # creating x var. with D, T and interact\n",
    "x = sm.add_constant(x)                                                 # adding constant to get an intercept\n",
    "cluster_var = df['cbd']                                                # cluster variable\n",
    "ols = sm.OLS(Y, x).fit(cov_type='cluster',                             # did\n",
    "                       cov_kwds={'groups': cluster_var})               # with cluster st.error \n",
    "print(ols.summary())                                                   # print the results\n",
    "\n",
    "# 39\n",
    "'''\n",
    "no Python code available\n",
    "'''\n",
    "\n",
    "# 40\n",
    "'''\n",
    "no Python code available\n",
    "'''\n",
    "\n",
    "# 41\n",
    "'''\n",
    "no Python code available\n",
    "'''\n",
    "\n",
    "# Chapter 8\n",
    "\n",
    "# 42\n",
    "np.random.seed(1)                                 # set seed\n",
    "out = sdid(california_prop99(),                   # synthetic did\n",
    "           unit=\"State\",                          # define unit\n",
    "           time=\"Year\",                           # define time\n",
    "           treatment=\"treated\",                   # define treatment\n",
    "           outcome=\"PacksPerCapita\")              # define outcome\n",
    "out = out.fit().vcov(method='placebo')            # placebo se \n",
    "out.summary().summary2                            # show results\n",
    "\n",
    "# 43\n",
    "import pandas as pd                                       # load pandas library\n",
    "import numpy as np                                        # load numpy library\n",
    "from synthdid.synthdid import Synthdid as sdid            # load synthdid library\n",
    "from synthdid.get_data import california_prop99           # load california data\n",
    "import matplotlib.pyplot as plt                           # load matplotlib library\n",
    "np.random.seed(1)                                         # set seed\n",
    "out = sdid(california_prop99(),                           # synthetic did\n",
    "           unit=\"State\",                                  # define unit\n",
    "           time=\"Year\",                                   # define time\n",
    "           treatment=\"treated\",                           # define treatment\n",
    "           outcome=\"PacksPerCapita\")                      # define outcome\n",
    "out.weights = np.zeros(19)                                # set weights\n",
    "out.fit(omega_intercept = False).vcov(method = 'placebo') # placebo se \n",
    "print(out.summary().summary2)                             # show results\n",
    "out.plot_outcomes()                                       # plot results\n",
    "\n",
    "# 44\n",
    "df = pd.read_csv('data/rdrobust_RDsenate.csv')                                  # load data\n",
    "R = df.margin                                                                   # running var. = margin of winning\n",
    "Y = df.vote                                                                     # outcome = vote share of democrats\n",
    "results = rdrobust(y=Y, x=R)                                                    # sharp rdd\n",
    "print(results)                                                                  # show results\n",
    "rdplot(y=Y, x=R)                                                                # plot results\n",
    "\n",
    "# 45\n",
    "'''\n",
    "no Python code available\n",
    "'''\n",
    "\n",
    "# 46\n",
    "\n",
    "df = pd.read_csv('data/rcp.csv')                                 # load rcp data\n",
    "Y = df['cn']                                                     # outcome\n",
    "R = df['elig_year']                                              # running var.\n",
    "D = df['retired']                                                # treatment\n",
    "results = rdrobust(y=Y, x=R, fuzzy=D)                            # fuzzy rdd\n",
    "print(results)                                                   # show results\n",
    "\n",
    "# 47\n",
    "df = pd.read_csv('data/rkd.csv')                                      # load rdk data\n",
    "Y = df['pers_total']                                                  # outcome\n",
    "R = df['forcing']                                                     # running var.\n",
    "D = df['costequalgrants']                                             # treatment\n",
    "results = rdrobust(y=Y, x=R, fuzzy=D, deriv=1)                        # fuzzy RKD\n",
    "print(results)                                                        # show results\n",
    "\n",
    "# 48\n",
    "'''\n",
    "no Python code available\n",
    "'''\n",
    "\n",
    "# 49\n",
    "'''\n",
    "no Python code available\n",
    "'''\n",
    "\n",
    "# 50\n",
    "'''\n",
    "no Python code available\n",
    "'''\n",
    "\n",
    "# 51\n",
    "'''\n",
    "no Python code available\n",
    "'''\n",
    "\n",
    "# 52\n",
    "'''\n",
    "no Python code available\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
